{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged Monitoring CSV saved to: C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_STD\\Merged_Monitoring_Recommendations.csv\n",
      "✅ Merged CSV saved for 'Module Summary': C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_STD\\Merged_Module_Summary.csv\n",
      "✅ Merged CSV saved for 'LOA Summary': C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_STD\\Merged_LOA_Summary.csv\n",
      "✅ Merged CSV saved for 'Reference Condition Comparison': C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_STD\\Merged_Reference_Condition_Comparison.csv\n",
      "✅ Merged CSV saved for 'Stressor Response Summary': C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_STD\\Merged_Stressor_Response_Summary.csv\n",
      "✅ Merged CSV saved for 'Spatial Co-Occurrence Summary': C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_STD\\Merged_Spatial_Co-Occurrence_Summary.csv\n",
      "✅ Merged CSV saved for 'RSCA Comparator Site Data': C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_STD\\Merged_RSCA_Comparator_Site_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the main directory where subfolders contain .xlsx files\n",
    "main_folder = r\"C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_STD\"  # Change this to your actual folder path\n",
    "\n",
    "# Define the worksheet names from \"Summary_Site_Data\"\n",
    "summary_sheet_names = [\n",
    "    \"Module Summary\",\n",
    "    \"LOA Summary\",\n",
    "    \"Reference Condition Comparison\",\n",
    "    \"Stressor Response Summary\",\n",
    "    \"Spatial Co-Occurrence Summary\",\n",
    "    \"RSCA Comparator Site Data\"\n",
    "]\n",
    "\n",
    "# Create dictionaries to store data for merging\n",
    "merged_summary_data = {sheet: [] for sheet in summary_sheet_names}  # Store Summary_Site_Data\n",
    "monitoring_list = []  # Store Monitoring_Recommendations\n",
    "\n",
    "# Walk through all subdirectories to find .xlsx files\n",
    "for root, _, files in os.walk(main_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.xlsx'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Process \"Monitoring_Recommendations\" files\n",
    "                if \"Monitoring_Recommendations\" in file:\n",
    "                    df = pd.read_excel(file_path, engine=\"openpyxl\")  # Read single-sheet Excel file\n",
    "                    df['Source_File'] = file  # Add filename as a new column\n",
    "                    monitoring_list.append(df)\n",
    "\n",
    "                # Process \"Summary_Site_Data\" files\n",
    "                elif \"Summary_Site_Data\" in file:\n",
    "                    sheets = pd.read_excel(file_path, sheet_name=None, engine=\"openpyxl\")  # Read all sheets\n",
    "\n",
    "                    for sheet in summary_sheet_names:\n",
    "                        if sheet in sheets:  # Ensure sheet exists\n",
    "                            df = sheets[sheet]\n",
    "                            #df['Source_File'] = file  # Add filename as a column\n",
    "                            #df['Sheet_Name'] = sheet  # Add sheet name as a column\n",
    "                            merged_summary_data[sheet].append(df)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {file_path}: {e}\")\n",
    "\n",
    "# ✅ Save \"Monitoring_Recommendations\" merged CSV\n",
    "if monitoring_list:\n",
    "    merged_monitoring = pd.concat(monitoring_list, ignore_index=True)\n",
    "    output_monitoring = os.path.join(main_folder, \"Merged_Monitoring_Recommendations.csv\")\n",
    "    merged_monitoring.to_csv(output_monitoring, index=False)\n",
    "    print(f\"✅ Merged Monitoring CSV saved to: {output_monitoring}\")\n",
    "else:\n",
    "    print(\"❌ No 'Monitoring_Recommendations' files found.\")\n",
    "\n",
    "# ✅ Save each \"Summary_Site_Data\" sheet separately\n",
    "for sheet, df_list in merged_summary_data.items():\n",
    "    if df_list:\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "        output_csv = os.path.join(main_folder, f\"Merged_{sheet.replace(' ', '_')}.csv\")\n",
    "        merged_df.to_csv(output_csv, index=False)\n",
    "        print(f\"✅ Merged CSV saved for '{sheet}': {output_csv}\")\n",
    "    else:\n",
    "        print(f\"❌ No data found for '{sheet}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "claudes re build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "                    handlers=[\n",
    "                        logging.FileHandler('excel_merger_log.txt'),\n",
    "                        logging.StreamHandler(sys.stdout)\n",
    "                    ])\n",
    "\n",
    "# Track timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Set the main directory where subfolders contain .xlsx files\n",
    "main_folder = r\"C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_Mod\"\n",
    "\n",
    "# Define the worksheet names from \"Summary_Site_Data\"\n",
    "summary_sheet_names = [\n",
    "    \"Module Summary\",\n",
    "    \"LOA Summary\",\n",
    "    \"Reference Condition Comparison\",\n",
    "    \"Stressor Response Summary\",\n",
    "    \"Spatial Co-Occurrence Summary\",\n",
    "    \"RSCA Comparator Site Data\"\n",
    "]\n",
    "\n",
    "# Function to process a single file with detailed error handling\n",
    "def process_file(file_path):\n",
    "    result = {\n",
    "        'monitoring': None,\n",
    "        'summary_sheets': {sheet: None for sheet in summary_sheet_names},\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        file = os.path.basename(file_path)\n",
    "        \n",
    "        # Process \"Monitoring_Recommendations\" files\n",
    "        if \"Monitoring_Recommendations\" in file:\n",
    "            try:\n",
    "                df = pd.read_excel(file_path, engine=\"openpyxl\")\n",
    "                df['Source_File'] = file\n",
    "                result['monitoring'] = df\n",
    "            except Exception as e:\n",
    "                result['error'] = f\"Monitoring file error: {str(e)}\"\n",
    "                logging.error(f\"Error processing {file_path}: {traceback.format_exc()}\")\n",
    "        \n",
    "        # Process \"Summary_Site_Data\" files\n",
    "        elif \"Summary_Site_Data\" in file:\n",
    "            try:\n",
    "                # Try reading specific sheets first\n",
    "                try:\n",
    "                    sheets = pd.read_excel(file_path, sheet_name=summary_sheet_names, engine=\"openpyxl\")\n",
    "                    for sheet in summary_sheet_names:\n",
    "                        if sheet in sheets:\n",
    "                            result['summary_sheets'][sheet] = sheets[sheet]\n",
    "                except ValueError:\n",
    "                    # If specific sheets fail, try reading all sheets\n",
    "                    sheets = pd.read_excel(file_path, sheet_name=None, engine=\"openpyxl\")\n",
    "                    for sheet in summary_sheet_names:\n",
    "                        if sheet in sheets:\n",
    "                            result['summary_sheets'][sheet] = sheets[sheet]\n",
    "            except Exception as e:\n",
    "                result['error'] = f\"Summary file error: {str(e)}\"\n",
    "                logging.error(f\"Error processing {file_path}: {traceback.format_exc()}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        result['error'] = f\"Unexpected error: {str(e)}\"\n",
    "        logging.error(f\"Unexpected error processing {file_path}: {traceback.format_exc()}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Find all Excel files\n",
    "excel_files = []\n",
    "for root, _, files in os.walk(main_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.xlsx'):\n",
    "            excel_files.append(os.path.join(root, file))\n",
    "\n",
    "logging.info(f\"Found {len(excel_files)} Excel files to process\")\n",
    "\n",
    "# Process files with progress bar\n",
    "monitoring_list = []\n",
    "merged_summary_data = {sheet: [] for sheet in summary_sheet_names}\n",
    "error_files = []\n",
    "\n",
    "# Process files in batches with more robust error handling\n",
    "batch_size = 100\n",
    "num_batches = (len(excel_files) + batch_size - 1) // batch_size\n",
    "\n",
    "for batch_num in range(num_batches):\n",
    "    start_idx = batch_num * batch_size\n",
    "    batch = excel_files[start_idx:start_idx+batch_size]\n",
    "    \n",
    "    logging.info(f\"Processing batch {batch_num + 1}/{num_batches}\")\n",
    "    \n",
    "    # Use a lower number of workers to reduce memory pressure\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max(1, os.cpu_count() - 1)) as executor:\n",
    "        try:\n",
    "            # Process the batch\n",
    "            results = list(tqdm(executor.map(process_file, batch), total=len(batch), \n",
    "                                desc=f\"Batch {batch_num + 1}\"))\n",
    "            \n",
    "            # Collect results from this batch\n",
    "            for result in results:\n",
    "                # Track files with errors\n",
    "                if result['error']:\n",
    "                    error_files.append({\n",
    "                        'file': batch[results.index(result)],\n",
    "                        'error': result['error']\n",
    "                    })\n",
    "                \n",
    "                # Collect monitoring data\n",
    "                if result['monitoring'] is not None:\n",
    "                    monitoring_list.append(result['monitoring'])\n",
    "                \n",
    "                # Collect summary sheet data\n",
    "                for sheet in summary_sheet_names:\n",
    "                    if result['summary_sheets'][sheet] is not None:\n",
    "                        merged_summary_data[sheet].append(result['summary_sheets'][sheet])\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Batch {batch_num + 1} processing error: {traceback.format_exc()}\")\n",
    "    \n",
    "    # Force garbage collection\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "# Log processing summary\n",
    "logging.info(f\"Finished processing all files in {time.time() - start_time:.1f} seconds\")\n",
    "\n",
    "# Log error files if any\n",
    "if error_files:\n",
    "    logging.warning(f\"Encountered errors in {len(error_files)} files\")\n",
    "    with open(os.path.join(main_folder, 'error_log.txt'), 'w') as f:\n",
    "        for error_file in error_files:\n",
    "            f.write(f\"File: {error_file['file']}\\nError: {error_file['error']}\\n\\n\")\n",
    "\n",
    "# Save \"Monitoring_Recommendations\" merged CSV\n",
    "if monitoring_list:\n",
    "    logging.info(\"Merging monitoring data...\")\n",
    "    merged_monitoring = pd.concat(monitoring_list, ignore_index=True)\n",
    "    output_monitoring = os.path.join(main_folder, \"Merged_Monitoring_Recommendations.csv\")\n",
    "    merged_monitoring.to_csv(output_monitoring, index=False)\n",
    "    logging.info(f\"✅ Merged Monitoring CSV saved to: {output_monitoring}\")\n",
    "else:\n",
    "    logging.warning(\"❌ No 'Monitoring_Recommendations' files found.\")\n",
    "\n",
    "# Save each \"Summary_Site_Data\" sheet separately\n",
    "for sheet, df_list in merged_summary_data.items():\n",
    "    if df_list:\n",
    "        logging.info(f\"Merging '{sheet}' data...\")\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "        output_csv = os.path.join(main_folder, f\"Merged_{sheet.replace(' ', '_')}.csv\")\n",
    "        merged_df.to_csv(output_csv, index=False)\n",
    "        logging.info(f\"✅ Merged CSV saved for '{sheet}': {output_csv}\")\n",
    "    else:\n",
    "        logging.warning(f\"❌ No data found for '{sheet}'\")\n",
    "\n",
    "logging.info(f\"Total execution time: {time.time() - start_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT rebuild of Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:30,693 - INFO: Found 2328 Excel files to process\n",
      "2025-03-04 10:12:30,695 - INFO: Processing batch 1/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:   0%|                                                                                                                                                                        | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:31,201 - ERROR: Batch 1 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:31,284 - INFO: Processing batch 2/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:31,584 - ERROR: Batch 2 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 766, in map\n",
      "    results = super().map(partial(_process_chunk, fn),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 610, in map\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 610, in <listcomp>\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 720, in submit\n",
      "    raise BrokenProcessPool(self._broken)\n",
      "concurrent.futures.process.BrokenProcessPool: A child process terminated abruptly, the process pool is not usable anymore\n",
      "\n",
      "2025-03-04 10:12:31,650 - INFO: Processing batch 3/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3:   0%|                                                                                                                                                                        | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:31,970 - ERROR: Batch 3 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:32,034 - INFO: Processing batch 4/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4:   0%|                                                                                                                                                                        | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:32,434 - ERROR: Batch 4 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:32,502 - INFO: Processing batch 5/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5:   0%|                                                                                                                                                                        | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:32,816 - ERROR: Batch 5 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:32,883 - INFO: Processing batch 6/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6:   0%|                                                                                                                                                                        | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:33,217 - ERROR: Batch 6 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:33,284 - INFO: Processing batch 7/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:33,566 - ERROR: Batch 7 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 766, in map\n",
      "    results = super().map(partial(_process_chunk, fn),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 610, in map\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 610, in <listcomp>\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 720, in submit\n",
      "    raise BrokenProcessPool(self._broken)\n",
      "concurrent.futures.process.BrokenProcessPool: A child process terminated abruptly, the process pool is not usable anymore\n",
      "\n",
      "2025-03-04 10:12:33,634 - INFO: Processing batch 8/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 8:   0%|                                                                                                                                                                        | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:33,956 - ERROR: Batch 8 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:34,033 - INFO: Processing batch 9/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 9:   0%|                                                                                                                                                                        | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:34,355 - ERROR: Batch 9 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:34,425 - INFO: Processing batch 10/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 10:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:34,773 - ERROR: Batch 10 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:34,842 - INFO: Processing batch 11/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 11:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:35,177 - ERROR: Batch 11 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:35,238 - INFO: Processing batch 12/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 12:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:35,574 - ERROR: Batch 12 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:35,645 - INFO: Processing batch 13/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 13:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:35,968 - ERROR: Batch 13 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:36,033 - INFO: Processing batch 14/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:36,346 - ERROR: Batch 14 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 766, in map\n",
      "    results = super().map(partial(_process_chunk, fn),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 610, in map\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 610, in <listcomp>\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 720, in submit\n",
      "    raise BrokenProcessPool(self._broken)\n",
      "concurrent.futures.process.BrokenProcessPool: A child process terminated abruptly, the process pool is not usable anymore\n",
      "\n",
      "2025-03-04 10:12:36,416 - INFO: Processing batch 15/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 15:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:36,722 - ERROR: Batch 15 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:36,792 - INFO: Processing batch 16/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 16:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:37,146 - ERROR: Batch 16 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:37,230 - INFO: Processing batch 17/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:37,525 - ERROR: Batch 17 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 766, in map\n",
      "    results = super().map(partial(_process_chunk, fn),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 610, in map\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 610, in <listcomp>\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 720, in submit\n",
      "    raise BrokenProcessPool(self._broken)\n",
      "concurrent.futures.process.BrokenProcessPool: A child process terminated abruptly, the process pool is not usable anymore\n",
      "\n",
      "2025-03-04 10:12:37,588 - INFO: Processing batch 18/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 18:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:37,922 - ERROR: Batch 18 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:37,994 - INFO: Processing batch 19/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 19:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:38,326 - ERROR: Batch 19 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:38,390 - INFO: Processing batch 20/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 20:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:38,695 - ERROR: Batch 20 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:38,763 - INFO: Processing batch 21/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 21:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:39,071 - ERROR: Batch 21 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:39,134 - INFO: Processing batch 22/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 22:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:39,483 - ERROR: Batch 22 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:39,557 - INFO: Processing batch 23/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 23:   0%|                                                                                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:39,864 - ERROR: Batch 23 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:39,925 - INFO: Processing batch 24/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 24:   0%|                                                                                                                                                                        | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:12:40,243 - ERROR: Batch 24 processing error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abels\\AppData\\Local\\Temp\\ipykernel_32416\\1271874543.py\", line 108, in <module>\n",
      "    results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\process.py\", line 575, in _chain_from_iterable_of_lists\n",
      "    for element in iterable:\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\abels\\.conda\\envs\\myJupenv\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "\n",
      "2025-03-04 10:12:40,312 - INFO: Finished processing all files in 9.8 seconds\n",
      "2025-03-04 10:12:40,314 - WARNING: ❌ No 'Monitoring_Recommendations' files found.\n",
      "2025-03-04 10:12:40,315 - WARNING: ❌ No data found for 'Module Summary'\n",
      "2025-03-04 10:12:40,316 - WARNING: ❌ No data found for 'LOA Summary'\n",
      "2025-03-04 10:12:40,318 - WARNING: ❌ No data found for 'Reference Condition Comparison'\n",
      "2025-03-04 10:12:40,319 - WARNING: ❌ No data found for 'Stressor Response Summary'\n",
      "2025-03-04 10:12:40,321 - WARNING: ❌ No data found for 'Spatial Co-Occurrence Summary'\n",
      "2025-03-04 10:12:40,322 - WARNING: ❌ No data found for 'RSCA Comparator Site Data'\n",
      "2025-03-04 10:12:40,323 - INFO: Total execution time: 9.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "# Configure logging with UTF-8 encoding for both file and stream handlers\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "stream_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s: %(message)s\"))\n",
    "file_handler = logging.FileHandler('excel_merger_log.txt', encoding='utf-8')\n",
    "file_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s: %(message)s\"))\n",
    "logging.getLogger().handlers = [file_handler, stream_handler]\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Track timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Set the main directory where subfolders contain .xlsx files\n",
    "main_folder = r\"C:\\Users\\abels\\Documents\\MyR\\RSCA_NoDB\\output\\SoCal_Mod\"\n",
    "\n",
    "# Define the worksheet names from \"Summary_Site_Data\"\n",
    "summary_sheet_names = [\n",
    "    \"Module Summary\",\n",
    "    \"LOA Summary\",\n",
    "    \"Reference Condition Comparison\",\n",
    "    \"Stressor Response Summary\",\n",
    "    \"Spatial Co-Occurrence Summary\",\n",
    "    \"RSCA Comparator Site Data\"\n",
    "]\n",
    "\n",
    "# Function to process a single file with detailed error handling\n",
    "def process_file(file_path):\n",
    "    result = {\n",
    "        'monitoring': None,\n",
    "        'summary_sheets': {sheet: None for sheet in summary_sheet_names},\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        file = os.path.basename(file_path)\n",
    "        \n",
    "        # Process \"Monitoring_Recommendations\" files\n",
    "        if \"Monitoring_Recommendations\" in file:\n",
    "            try:\n",
    "                df = pd.read_excel(file_path, engine=\"openpyxl\")\n",
    "                df['Source_File'] = file\n",
    "                result['monitoring'] = df\n",
    "            except Exception as e:\n",
    "                result['error'] = f\"Monitoring file error: {str(e)}\"\n",
    "                logging.error(f\"Error processing {file_path}:\\n{traceback.format_exc()}\")\n",
    "        \n",
    "        # Process \"Summary_Site_Data\" files\n",
    "        elif \"Summary_Site_Data\" in file:\n",
    "            try:\n",
    "                # Try reading specific sheets first\n",
    "                try:\n",
    "                    sheets = pd.read_excel(file_path, sheet_name=summary_sheet_names, engine=\"openpyxl\")\n",
    "                    for sheet in summary_sheet_names:\n",
    "                        if sheet in sheets:\n",
    "                            result['summary_sheets'][sheet] = sheets[sheet]\n",
    "                except ValueError:\n",
    "                    # If specific sheets fail, try reading all sheets\n",
    "                    sheets = pd.read_excel(file_path, sheet_name=None, engine=\"openpyxl\")\n",
    "                    for sheet in summary_sheet_names:\n",
    "                        if sheet in sheets:\n",
    "                            result['summary_sheets'][sheet] = sheets[sheet]\n",
    "            except Exception as e:\n",
    "                result['error'] = f\"Summary file error: {str(e)}\"\n",
    "                logging.error(f\"Error processing {file_path}:\\n{traceback.format_exc()}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        result['error'] = f\"Unexpected error: {str(e)}\"\n",
    "        logging.error(f\"Unexpected error processing {file_path}:\\n{traceback.format_exc()}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Find all Excel files\n",
    "excel_files = []\n",
    "for root, _, files in os.walk(main_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.xlsx'):\n",
    "            excel_files.append(os.path.join(root, file))\n",
    "\n",
    "logging.info(f\"Found {len(excel_files)} Excel files to process\")\n",
    "\n",
    "# Prepare lists for collected data\n",
    "monitoring_list = []\n",
    "merged_summary_data = {sheet: [] for sheet in summary_sheet_names}\n",
    "error_files = []\n",
    "\n",
    "# Process files in batches\n",
    "batch_size = 100\n",
    "num_batches = (len(excel_files) + batch_size - 1) // batch_size\n",
    "\n",
    "for batch_num in range(num_batches):\n",
    "    start_idx = batch_num * batch_size\n",
    "    batch = excel_files[start_idx:start_idx+batch_size]\n",
    "    \n",
    "    logging.info(f\"Processing batch {batch_num + 1}/{num_batches}\")\n",
    "    \n",
    "    # Use a lower number of workers to reduce memory pressure\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max(1, os.cpu_count() - 1)) as executor:\n",
    "        try:\n",
    "            # Process the batch with a progress bar\n",
    "            results = list(tqdm(executor.map(process_file, batch), total=len(batch),\n",
    "                                desc=f\"Batch {batch_num + 1}\"))\n",
    "            \n",
    "            # Collect results from this batch using enumerate to avoid index lookup issues\n",
    "            for i, result in enumerate(results):\n",
    "                file_processed = batch[i]\n",
    "                if result['error']:\n",
    "                    error_files.append({'file': file_processed, 'error': result['error']})\n",
    "                \n",
    "                if result['monitoring'] is not None:\n",
    "                    monitoring_list.append(result['monitoring'])\n",
    "                \n",
    "                for sheet in summary_sheet_names:\n",
    "                    if result['summary_sheets'][sheet] is not None:\n",
    "                        merged_summary_data[sheet].append(result['summary_sheets'][sheet])\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Batch {batch_num + 1} processing error:\\n{traceback.format_exc()}\")\n",
    "    \n",
    "    # Force garbage collection\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "logging.info(f\"Finished processing all files in {time.time() - start_time:.1f} seconds\")\n",
    "\n",
    "# Log error files if any\n",
    "if error_files:\n",
    "    logging.warning(f\"Encountered errors in {len(error_files)} files\")\n",
    "    with open(os.path.join(main_folder, 'error_log.txt'), 'w', encoding='utf-8') as f:\n",
    "        for error_file in error_files:\n",
    "            f.write(f\"File: {error_file['file']}\\nError: {error_file['error']}\\n\\n\")\n",
    "\n",
    "# Save \"Monitoring_Recommendations\" merged CSV\n",
    "if monitoring_list:\n",
    "    logging.info(\"Merging monitoring data...\")\n",
    "    merged_monitoring = pd.concat(monitoring_list, ignore_index=True)\n",
    "    output_monitoring = os.path.join(main_folder, \"Merged_Monitoring_Recommendations.csv\")\n",
    "    merged_monitoring.to_csv(output_monitoring, index=False)\n",
    "    logging.info(f\"✅ Merged Monitoring CSV saved to: {output_monitoring}\")\n",
    "else:\n",
    "    logging.warning(\"❌ No 'Monitoring_Recommendations' files found.\")\n",
    "\n",
    "# Save each \"Summary_Site_Data\" sheet separately\n",
    "for sheet, df_list in merged_summary_data.items():\n",
    "    if df_list:\n",
    "        logging.info(f\"Merging '{sheet}' data...\")\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "        output_csv = os.path.join(main_folder, f\"Merged_{sheet.replace(' ', '_')}.csv\")\n",
    "        merged_df.to_csv(output_csv, index=False)\n",
    "        logging.info(f\"✅ Merged CSV saved for '{sheet}': {output_csv}\")\n",
    "    else:\n",
    "        logging.warning(f\"❌ No data found for '{sheet}'\")\n",
    "\n",
    "logging.info(f\"Total execution time: {time.time() - start_time:.1f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
